# # Model and training configuration
# # python -u main_informer.py --model informer --data ETTh1 --features M --seq_len 336 --label_len 336 --pred_len 720 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 5
# model:
#   name: "informer"
#   data: "ETTh1"
#   features: "M"
#   target: "OT"
#   freq: "h"
#   seq_len: 336
#   label_len: 336
#   pred_len: 720
#   enc_in: 7
#   dec_in: 7
#   c_out: 7
#   factor: 5
#   d_model: 512
#   n_heads: 8
#   e_layers: 2
#   d_layers: 1
#   d_ff: 2048
#   dropout: 0.05
#   attn: "prob"
#   embed: "timeF"
#   activation: "gelu"
#   distil: true
#   output_attention: False
#   mix: true
#   padding: 0

# paths:
#   root_path: "./data/ETT/"
#   data_path: "ETTh1.csv"
#   checkpoints: "./informer_checkpoints"
#   checkpoint_path: "informer_ETTh1_ftM_sl336_ll336_pl720_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_Exp_4"

# training:
#   batch_size: 32
#   learning_rate: 0.0001
#   loss: "mse"
#   lradj: "type1"
#   use_amp: False
#   num_workers: 0
#   itr: 5
#   train_epochs: 6
#   patience: 3
#   des: "Exp"
#   use_gpu: True
#   gpu: 0
#   use_multi_gpu: False
#   devices: "0,1,2,3"

# wandb:
#   batch_size: 32
#   hidden_size: 128
#   num_layers: 2
#   dropout_rate: 0.1
#   lr: 0.0001
#   epochs: 6
#   alpha: 0.5


# python -u main_informer.py --model informer --data ETTh1 --features M --seq_len 48 --label_len 48 --pred_len 24 --e_layers 2 --d_layers 1 --attn prob --des 'Exp' --itr 5 --factor 3
model:
  name: "informer"
  data: "ETTh1"
  features: "M"
  target: "OT"
  freq: "h"
  seq_len: 48
  label_len: 48
  pred_len: 24
  enc_in: 7
  dec_in: 7
  c_out: 7
  factor: 3
  d_model: 512
  n_heads: 8
  e_layers: 2
  d_layers: 1
  d_ff: 2048
  dropout: 0.05
  attn: "prob"
  embed: "timeF"
  activation: "gelu"
  distil: true
  output_attention: False
  mix: true
  padding: 0

paths:
  root_path: "./data/ETT/"
  data_path: "ETTh1.csv"
  checkpoints: "./informer_checkpoints"
  checkpoint_path: "informer_ETTh1_ftM_sl48_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxTrue_Exp_4"

training:
  batch_size: 32
  learning_rate: 0.0001
  loss: "mse"
  lradj: "type1"
  use_amp: False
  num_workers: 0
  itr: 5
  train_epochs: 6
  patience: 3
  des: "Exp"
  use_gpu: True
  gpu: 0
  use_multi_gpu: False
  devices: "0,1,2,3"

wandb:
  batch_size: 32
  hidden_size: 128
  num_layers: 2
  dropout_rate: 0.1
  lr: 0.0001
  epochs: 6
  alpha: 0.5